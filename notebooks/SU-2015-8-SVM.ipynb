{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sveučilište u Zagrebu<br>\n",
    "Fakultet elektrotehnike i računarstva\n",
    "\n",
    "# Strojno učenje\n",
    "\n",
    "<a href=\"http://www.fer.unizg.hr/predmet/su\">http://www.fer.unizg.hr/predmet/su</a>\n",
    "\n",
    "Ak. god. 2015./2016.\n",
    "\n",
    "# Bilježnica 8: Stroj potpornih vektora (SVM)\n",
    "\n",
    "(c) 2015 Jan Šnajder\n",
    "\n",
    "<i>Verzija: 0.1 (2015-12-08)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sadržaj:\n",
    "\n",
    "* Uvod\n",
    "\n",
    "* Problem maksimalne margine\n",
    "\n",
    "* Optimizacija uz ograničenja\n",
    "\n",
    "* Metoda Lagrangeovih multiplikatora\n",
    "\n",
    "* Dualna formulacija problema maksimalne margine\n",
    "\n",
    "* Meka margina\n",
    "\n",
    "* Gubitak zglobnice\n",
    "\n",
    "* Jezgreni trik\n",
    "\n",
    "* Mercerove jezgre\n",
    "\n",
    "* Optimizacija hiperparametara\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uvod\n",
    "\n",
    "\n",
    "* Vrlo učinkovit **diskriminativan model**\n",
    "\n",
    "\n",
    "* Podsjetnik: Algoritam strojnog učenja definiran je \n",
    "  1. modelom\n",
    "  * pogreškom\n",
    "  * optimizacijskim postupkom\n",
    "    \n",
    "    \n",
    "* Model:\n",
    "    \n",
    "$$\n",
    "    h(\\mathbf{x}) = \\mathbf{w}^\\intercal\\boldsymbol{\\phi}(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "\n",
    "* Dakle, to je poopćeni linearan model bez funkcije preslikavanja\n",
    "\n",
    "\n",
    "* Gornja definicija modela je tzv. **primarna formulacija**\n",
    "\n",
    "\n",
    "* Postoji i **dualna formulacija**:\n",
    "  * Umjesto da značajke novog primjera množimo težinama $\\mathbf{w}$, možemo za novi primjer izračunati koliko je sličan primjerima iz skupa za učenje i na temelju toga odrediti klasifikaciju\n",
    "  * Model efektivno postaje **neparametarski**!\n",
    "  \n",
    "  \n",
    "* U dualnoj formulaciji možemo iskoristiti tzv. **jezgreni trik**, koji nam omogućava jeftino preslikavanje primjera u prostor više dimenzije (a time i nelinearnost modela)\n",
    "  * SVM je jedna vrsta tzv. **jezgrenog stroja** (engl. *kernel machine*)\n",
    "\n",
    "\n",
    "* Model je jednostavan, no definicija pogreške i optimizacijskog postupka su nešto složeniji\n",
    "\n",
    "\n",
    "* Osnovna ideja: primjere dviju klasa razdvojiti tako da je prostor između njih što veći $\\Rightarrow$ tzv. **maksimalna margina**\n",
    "\n",
    "\n",
    "* Opravdanje: generalizacija će biti najbolja onda kada granicu između klasa povućemo točno po sredini margine\n",
    "\n",
    "\n",
    "* Do sada smo optimizacijski problem definirali tako da smo\n",
    "  * krenuli od log-izglednosti pa izveli MLE (Naivan bayes)\n",
    "  * krenuli od funkcije gubitka pa izveli funkciju pogreške (linearna regresija) i napravili analitičku minimizaciju\n",
    "  * krenuli od funkcije pogreške pa izveli funkciju gubitka (logistička regresija, perceptron) i iskoristili je za gradijentni spust\n",
    "  \n",
    "  \n",
    "* Kod SVM-a, krenut ćemo odmah od onoga što u konačnici želimo dobiti: maksimalnu marginu $\\Rightarrow$ to je ono što SVM optimizira\n",
    "\n",
    "\n",
    "* Ići ćemo \"klasičnim pristupom\": formalizirati to kao problem **kvadratnog programiranja**\n",
    "\n",
    "\n",
    "* Naknadno ćemo iz toga izvesti funkciju gubitka (i funkciju pogreške), ali samo radi usporedbe s drugim algoritmima\n",
    "\n",
    "\n",
    "> **Sinopsis:**\n",
    "> \n",
    "> * Prvo ćemo se fokusirati na **linearan model** i **linearno odvojive probleme** (tvrda granica)\n",
    "  * Matematika: Lagrangeovi multiplikatori\n",
    "> \n",
    "> * Zatim ćemo proširiti **linearan model** tako da može raditi s **linearno neodvojivim problemima** (meka granica)\n",
    "> \n",
    "> * Na kraju ćemo proširiti na **nelinearan model** (jezgreni trik)\n",
    ">   * Matematika: Mercerove jezgre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem maksimalne margine\n",
    "\n",
    "* Model:\n",
    "$$\n",
    "h(\\mathbf{x}) = \\mathbf{w}^\\intercal x + w_0\n",
    "$$\n",
    "\n",
    "\n",
    "* Oznake primjera za učenje: $y\\in\\{-1,+1\\}$\n",
    "\n",
    "\n",
    "* Granica između klasa: hiperravnina $h(\\mathbf{x})=0$\n",
    "\n",
    "\n",
    "* Predikcija klase: $y=\\mathrm{sgn}(h(\\mathbf{x}))$\n",
    "\n",
    "\n",
    "* Pretpostavimo da su primjeri iz $\\mathcal{D}$ **linearno odvojivi**\n",
    "\n",
    "\n",
    "* Onda postoji $\\mathbf{w}$ i $w_0$ takvi da\n",
    "$$\n",
    "\\begin{align*}\n",
    "h(\\mathbf{x}^{(i)}) \\geq 0 & \\quad\\text{za svaki $y^{(i)}=+1$}\\\\\n",
    "h(\\mathbf{x}^{(i)}) < 0 & \\quad\\text{za svaki $y^{(i)}=-1$}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "* Kraće, postoje $\\mathbf{w}$ i $w_0$ takvi da\n",
    "$$\n",
    "\\forall(\\mathbf{x}^{(i)},y^{(i)}) \\in \\mathcal{D}.\\ y^{(i)}h(\\mathbf{x}^{(i)})\\geq 0\n",
    "$$\n",
    "\n",
    "\n",
    "* Postoji beskonačno mnogo rješenja za $\\mathbf{w}$ i $w_0$ (prostor inačica je beskonačan)\n",
    "\n",
    "\n",
    "* No nas zanima rješenje **maksimalne margine** $\\Rightarrow$ induktivna pristranost preferencijom\n",
    "\n",
    "\n",
    "* **Margina = udaljenost hiperravnine do najbližeg primjera**\n",
    "\n",
    "\n",
    "* Ako maksimiziramo marginu, onda će hiperravnina prolaziti točno na pola puta između dva primjera\n",
    "\n",
    "\n",
    "#### Formulacija optimizacijskog problema\n",
    "\n",
    "\n",
    "* Predznačena udaljenost primjera od hiperravnine je\n",
    "\n",
    "$$\n",
    "d = \\frac{h(\\mathbf{x})}{\\|\\mathbf{w}\\|}\n",
    "$$\n",
    "\n",
    "\n",
    "* Nas zanimaju samo hiperravnine koje ispravno klasificiraju primjere. U tom slučaju **apsolutna** udaljenost primjera do hiperravnine je:\n",
    "\n",
    "$$\n",
    "\\frac{y^{(i)}h(\\mathbf{x})}{\\|\\mathbf{w}\\|} = \n",
    "\\frac{y^{(i)}(\\mathbf{w}^\\intercal\\mathbf{x}^{(i)}+w_0)}{\\|\\mathbf{w}\\|}\n",
    "$$\n",
    "\n",
    "\n",
    "* Po definiciji, margina je udaljenost hiperravnine do najbližeg primjera:\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\|\\mathbf{w}\\|}\\mathrm{min}_i\\big\\{y^{(i)}(\\mathbf{w}^\\intercal\\mathbf{x} + w_0)\\big\\}\n",
    "$$\n",
    "\n",
    "\n",
    "* Tu udaljenost želimo maksimizirati:\n",
    "\n",
    "$$\n",
    "\\mathrm{argmax}_{\\mathbf{w},w_0}\\Big\\{\\frac{1}{\\|\\mathbf{w}\\|}\\mathrm{min}_i\\big\\{y^{(i)}(\\mathbf{w}^\\intercal\\mathbf{x} + w_0)\\big\\}\\Big\\}\n",
    "$$\n",
    "\n",
    "\n",
    "* Ako je $\\mathcal{D}$ linearno odvojiv, onda postoji samo jedna takva margina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pojednostavljenje optimizacijskog problema\n",
    "\n",
    "\n",
    "* Gornji problem teško je riješiti izravno (min unutar max)\n",
    "\n",
    "\n",
    "* Vektor $(\\mathbf{w},w_0)$ možemo pomnožiti s proizvoljnom konstantom, a da to ne utječe na udaljenosti između primjera i hiperravnine:\n",
    "\n",
    "$$\n",
    "d=\\frac{h(\\mathbf{x})}{\\|\\mathbf{w}\\|}=\n",
    "\\frac{\\color{red}{\\alpha}\\mathbf{w}^\\intercal\\mathbf{x}+\\color{red}{\\alpha}w_0}{\\|\\color{red}{\\alpha}\\mathbf{w}\\|}=\n",
    "\\frac{\\color{red}{\\alpha}(\\mathbf{w}^\\intercal\\mathbf{x}+w_0)}{\\color{red}{\\alpha}\\|\\mathbf{w}\\|}=\n",
    "\\frac{\\mathbf{w}^\\intercal\\mathbf{x}+w_0}{\\|\\mathbf{w}\\|}\n",
    "$$\n",
    "\n",
    "\n",
    "* Kako bismo pojednostavili problem, možemo definirati da za primjer $\\mathbf{x}^{(i)}$ koji je najbliži margini vrijedi\n",
    "\n",
    "$$\n",
    "y^{(i)}(\\mathbf{w}^\\intercal\\mathbf{x}+w_0)=1\n",
    "$$\n",
    "\n",
    "\n",
    "* Svi ostali primjeri jednako su blizu margine ili su od nje još udaljeniji:\n",
    "\n",
    "$$\n",
    "y^{(i)}(\\mathbf{w}^\\intercal\\mathbf{x}+w_0) \\geq 1, \\qquad n=1,\\dots,N\n",
    "$$\n",
    "\n",
    "\n",
    "* Za primjere za koje $y^{(i)}h(\\mathbf{x})=1$ kažemo da su ograničenja **aktivna**, dok su za ostale primjere ograničenja neaktivna \n",
    "  * (Primjeri za koje su ograničenja aktivna zovemo potpornim vektorima, ali o tome više kasnije)\n",
    "\n",
    "\n",
    "* Uvijek će postojati barem **dva** aktivna ograničenja\n",
    "\n",
    "\n",
    "* [Skica: maksimalna margina]\n",
    "\n",
    "\n",
    "* Dakle, umjesto\n",
    "$$\n",
    "\\mathrm{argmax}_{\\mathbf{w},w_0}\\Big\\{\\frac{1}{\\|\\mathbf{w}\\|}\\underbrace{\\mathrm{min}_i\\big\\{y^{(i)}(\\mathbf{w}^\\intercal\\mathbf{x} + w_0)\\big\\}}_{=1}\\Big\\}\n",
    "$$\n",
    "mi sada maksimiziramo\n",
    "$$\n",
    "\\mathrm{argmax}_{\\mathbf{w},w_0}\\frac{1}{\\|\\mathbf{w}\\|}\n",
    "$$\n",
    "uz ograničenja\n",
    "$$\n",
    "y^{(i)}(\\mathbf{w}^\\intercal\\mathbf{x}+w_0) \\geq 1, \\qquad n=1,\\dots,N\n",
    "$$\n",
    "\n",
    "\n",
    "* Maksimizator od $\\frac{1}{\\|\\mathbf{w}\\|}$ ekvivalentan je minimizatoru od $\\|\\mathbf{w}\\|=\\sqrt{\\mathbf{w}^\\intercal\\mathbf{w}}$, a taj je ekvivalentan minimizatoru od $\\|\\mathbf{w}\\|^2$. Još ćemo pomnožiti s $\\frac{1}{2}$ radi kasnije matematičke jednostavnosti\n",
    "\n",
    "\n",
    "* Konačna formulacija optimizacijskog problema maksimalne margine:\n",
    "\n",
    "> $\\mathrm{argmin}_{\\mathbf{w},w_0}\\frac{1}{2}\\|\\mathbf{w}\\|^2$\n",
    "\n",
    "> tako da $\\quad y^{(i)}(\\mathbf{w}^\\intercal\\mathbf{x}+w_0) \\geq 1, \\quad n=1,\\dots,N$\n",
    "\n",
    "\n",
    "* Naš optimizacijski problem sveo se na ciljnu funkciju koju želimo optimirati i ograničenja koja pritom moramo poštovati: tipičan problem **konveksne optimizacije uz ograničenja**, točnije **kvadratnog programiranja**\n",
    "  * \"Programiranje\" = matematičko programiranje = (matematička) optimizacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizacija uz ograničenja\n",
    "\n",
    "\n",
    "* Optimizacijski problem $\\Rightarrow$ Optimizacija uz ograničenja $\\Rightarrow$ Konveksni optimizacijski problem $\\Rightarrow$ Kvadratno programiranje\n",
    "\n",
    "\n",
    "* Optimizacijski problem uz ograničenja (standardni oblik):\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimizirati} &\\quad f(\\mathbf{x})\\\\\n",
    "\\text{uz ograničenja} &\\quad g_i(\\mathbf{x})\\leq0,\\quad i=1,\\dots,m\\\\\n",
    "&\\quad h_i(\\mathbf{x}) = 0,\\quad i=1,\\dots,p\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "* $f : \\mathbb{R}^n\\to\\mathbb{R}$ je **ciljna funkcija** (engl. *objective function*\n",
    "* $h_i : \\mathbb{R}^n\\to\\mathbb{R}$ su **ograničenja\n",
    "jednakosti** (engl. *equality constraints*)\n",
    "* $g_i:\\mathbb{R}^n\\to\\mathbb{R}$ su **ograničenja nejednakosti** (engl. *inequality constraints*)\n",
    "\n",
    "\n",
    "* **NB:** Sva ograničenja (ne)jednakosti mogu se se svesti na standardni oblik\n",
    "\n",
    "\n",
    "* Tražimo minimum koji zadovoljava sva ograničenja\n",
    "* Točke koje zadovoljavaju rješenja zovemo **ostvarivim\n",
    "točkama** (engl. *feasible points*)\n",
    "\n",
    "\n",
    "* Konveksni optimizacijski problem:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimizirati} &\\quad f(\\mathbf{x})\\ \\color{red}{\\text{$\\Rightarrow$ konveksna}}\\\\\n",
    "\\text{uz ograničenja} &\\quad g_i(\\mathbf{x})\\leq0,\\quad i=1,\\dots,m\\\\\n",
    "&\\quad \\mathbf{a}_i^\\intercal\\mathbf{x} - b_i = 0,\\quad i=1,\\dots,p\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "* Kvadratni program:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{minimizirati} &\\quad \\frac{1}{2}\\mathbf{x}^\\intercal P\\mathbf{x} + \\mathbf{q}^\\intercal\\mathbf{x} + r\\ \\color{red} {\\text{$\\Rightarrow$ kvadratna funkcija}}\\\\\n",
    "\\text{uz ograničenja} &\\quad G\\mathbf{x}\\leq\\mathbf{h}\\\\\n",
    "&\\quad A\\mathbf{x}=\\mathbf{b}\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metoda Lagrangeovih multiplikatora\n",
    "\n",
    "* Kvadratni program može se riješiti metodom **Langrangeovih multiplikatora**\n",
    "  * Točnije: **proširen Lagrangeov postupak** (engl. *augmented Lagrangian method*), jer imamo ograničenja nejednakosti (izvorna metoda dopušta samo ograničenja jednakosti)\n",
    "\n",
    "\n",
    "* Lagrangeovi multiplikatori mogu se koristiti općenito za optimizaciju s ograničenjima (problem ne mora biti konveksan)\n",
    "\n",
    "\n",
    "* Pripada skupini **metoda s kaznom** (engl. *penalty methods*)\n",
    "\n",
    "\n",
    "* Ideja: umjesto ograničenog problema, riješiti niz neograničenih problema koji uključuju kaznu za kršenje ograničenja\n",
    "\n",
    "\n",
    "* Alternativa: **metode unutarnje točke** (engl. *interior-point methods*, *barrier methods*)\n",
    "\n",
    "#### Lagrangeova funkcija\n",
    "\n",
    "* **Lagrangeova funkcija** izravno ugrađuje ograničenja u ciljnu funkciju\n",
    "\n",
    "\n",
    "* [Skica ideje]\n",
    "\n",
    "\n",
    "* Početni problem:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{minimizirati} &\\quad f(\\mathbf{x})\\\\\n",
    "\\text{uz ograničenja} &\\quad g_i(\\mathbf{x})\\leq0,\\quad i=1,\\dots,m\\\\\n",
    " &\\quad h_i(\\mathbf{x}) = 0,\\quad i=1,\\dots,p\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "* Lagrangeova funkcija:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "L(\\mathbf{x},\\color{red}{\\boldsymbol\\alpha},\\color{red}{\\boldsymbol\\beta}) = f(\\mathbf{x}) + \\sum_{i=1}^m\\color{red}{\\alpha_i} g(\\mathbf{x}) + \\sum_{i=1}^p\\color{red}{\\beta_i}\n",
    "h(\\mathbf{x})\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "* Dobili smo neograničeni problem optimizacije: optimum Lagrangeove funkcije odgovara optimimu odgovarajućeg problema s ograničenjim\n",
    "\n",
    "\n",
    "* Vrijednosti $\\alpha_i$ i $\\beta_i$ su **Lagrangeovi multiplikatori** (množitelji) za ograničenja nejednakosti odnosno jednakosti\n",
    "\n",
    "\n",
    "* Za vrijednosti $\\alpha_i$ vrijede takozvani **Karush-Kuhn-Tuckerovi (KKT)** uvjeti:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\alpha_i &\\geq 0,\\quad i=1,\\dots,p\\\\\n",
    "\\alpha_i g_i(\\mathbf{x}) &= 0,\\quad i=1,\\dots,p\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Lagrangeova dualnost\n",
    "\n",
    "\n",
    "* Načelo dualnosti u teoriji optimizacije:\n",
    "  * **Primarni problem** (engl. *primal problem*): minimizacija funkcije $f(\\mathbf{x})$\n",
    "  * **Dualni problem**: nalaženje donje granice primarnog problema (\"minumum ne može biti manji od $\\mathbf{x}$\")\n",
    "\n",
    "\n",
    "* [Skica: primal-dual sedlo]\n",
    "\n",
    "\n",
    "* Općenito, rješenja primarnog i dualnog problema se ne preklapaju već postoji **dualni procjep**\n",
    "\n",
    "\n",
    "* Uz određene uvjete, kod konveksne optimizacije dualni procjep jednak je nuli $\\Rightarrow$ **jaka dualnost**\n",
    "\n",
    "\n",
    "* To znači da je rješenje dualnog problema ujedno i rješenje primarnog problema\n",
    "\n",
    "\n",
    "* Dakle, ako nam je tako pogodnije, možemo rješavati dualni problem umjesto primarnog\n",
    "\n",
    "\n",
    "* U nastavku promatramo Lagrangeovu dualnost\n",
    "\n",
    "\n",
    "* Lagrangeova funkcija (NSO: samo s ograničenjima jednakosti):\n",
    "\n",
    "$$\n",
    "L(\\mathbf{x},\\boldsymbol\\alpha) = f(\\mathbf{x}) + \\sum_i\\alpha_i g_i(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "\n",
    "* To je fukcija od $\\mathbf{x}$ (**primarne varijable**) i $\\boldsymbol\\alpha$ (**dualne varijable**)\n",
    "\n",
    "\n",
    "* Optimum:\n",
    "$$\n",
    "L(\\mathbf{x}^*,\\boldsymbol\\alpha^*) = \\min_{\\mathbf{x},\\boldsymbol\\alpha} L(\\mathbf{x},\\boldsymbol\\alpha)\n",
    "$$\n",
    "\n",
    "\n",
    "* Vrijednost za $\\mathbf{x}^*$ nalazimo rješavanjem sustava:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\nabla f(\\mathbf{x}) + \\nabla \\sum_i\\alpha_i h_i(\\mathbf{x}) = 0\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "* To rješenje ne mora dovesti do uklanjanja dualnih varijabli! Općenito, dobit ćemo rješenje koje mimizira $\\mathbf{x}$ za neki zadani $\\boldsymbol\\alpha$:\n",
    "$$\n",
    "\\tilde{L}(\\boldsymbol\\alpha)= \\min_{\\mathbf{x}}L(\\mathbf{x},\\boldsymbol\\alpha) = \\min_{\\mathbf{x}}\\Big(f(\\mathbf{x}) + \\sum_i\n",
    "\\alpha_i g(\\mathbf{x})\\Big)\n",
    "$$\n",
    "$\\Rightarrow$ **Dualna Lagrangeova funkcija**\n",
    "\n",
    "\n",
    "* Sigurno vrijedi:\n",
    "$$\n",
    "\\tilde{L}(\\boldsymbol\\alpha) \\leq L(\\mathbf{x}^*,\\boldsymbol\\alpha)\n",
    "$$\n",
    "$\\Rightarrow$ Dualna Lagrangeova funkcija je **donja ograda** primarnog problema\n",
    "\n",
    "\n",
    "* U točki $\\boldsymbol\\alpha^*$ vrijedi $\\tilde{L}(\\boldsymbol\\alpha^*)=L(\\mathbf{x}^*,\\boldsymbol\\alpha^*)$\n",
    "\n",
    "\n",
    "* Kako bismo pronašli $\\boldsymbol\\alpha^*$, moramo maksimizirati\n",
    "donju ogradu, tj. riješiti sljedeći konveksni problem:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{maksimizirati} &\\quad \\tilde{L}(\\boldsymbol\\alpha)\\\\\n",
    "\\text{uz ograničenja} &\\quad \\alpha_i\\geq 0,\\quad i=1,\\dots,m\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "* **NB:** minimizacija ciljne funkcije $\\Leftrightarrow$ maksimizacija dualne funkcije"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dualna formulacija problema maksimalne margine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Optimizacijski problem maksimalne margine:\n",
    "\n",
    "> $\\mathrm{argmin}_{\\mathbf{w},w_0}\\frac{1}{2}\\|\\mathbf{w}\\|^2$\n",
    "\n",
    "> tako da $\\quad y^{(i)}(\\mathbf{w}^\\intercal\\mathbf{x}+w_0) \\geq 1, \\quad n=1,\\dots,N$\n",
    "\n",
    "\n",
    "* Odgovarajuća Lagrangeova funkcija:\n",
    "\n",
    "$$\n",
    "L(\\mathbf{w},w_0,\\color{red}{\\boldsymbol\\alpha})=\\frac{1}{2}\\|\\mathbf{w}\\|^2 -\n",
    "\\sum_{i=1}^N\\color{red}{\\alpha_i}\\Big\\{y^{(i)}\\big(\\mathbf{w}^\\intercal\\mathbf{x}^{(i)}+w_0\\big)-1\\Big\\}\n",
    "$$\n",
    "\n",
    "\n",
    "*  $\\color{red}{\\boldsymbol\\alpha=(\\alpha_1,\\dots,\\alpha_N)}$ je vektor Lagrangeovih multiplikatora, po jedan za svako ograničenje\n",
    "\n",
    "\n",
    "* Prelazimo na **dualnu formulaciju** problema jer je ta formulacija jednostavnija (optimirat ćemo samo po $\\boldsymbol\\alpha$, a postoje i neke druge prednosti)\n",
    "\n",
    "\n",
    "* Minimizator $(\\mathbf{w}^*, w_0^*)$: deriviranje po $\\mathbf{w}$ odnosno $w_0$ i izjednačavanje s nulom:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{w} &= \\sum_{i=1}^N \\alpha_i y^{(i)}\\mathbf{x}^{(i)}\\\\\n",
    "0 &= \\sum_{i=1}^N\\alpha_i y^{(i)}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dualna Lagrangeova funkcija:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\tilde{L}(\\boldsymbol\\alpha) &=\n",
    "\\frac{1}{2}\\|\\mathbf{w}\\|^2 -\\sum_{i=1}^N\\alpha_i\\Big\\{y^{(i)}\\big(\\mathbf{w}^\\intercal\\mathbf{x}^{(i)}+w_0\\big)-1\\Big\\}\\\\\n",
    "&= \n",
    "\\frac{1}{2}\\|\\mathbf{w}\\|^2\n",
    "-\\sum_{i=1}^N\\alpha_i y^{(i)}\\mathbf{w}^\\intercal\\mathbf{x}^{(i)}\n",
    "\\color{gray}{\\underbrace{-w_0 \\sum_{i=1}^N\\alpha_iy^{(i)}}_{=0}} + \n",
    "\\sum_{i=1}^N\\alpha_i\\\\\n",
    "&= \\nonumber\n",
    "\\frac{1}{2}\\sum_{i=1}^N\\alpha_i y^{(i)}(\\mathbf{x}^{(i)})^\\intercal\\sum_{j=1}^N\\alpha_j y^{(j)}\\mathbf{x}^{(j)}\n",
    "-\n",
    "\\sum_{i=1}^N\\alpha_i y^{(i)}(\\mathbf{x}^{(i)})^\\intercal\\sum_{j=1}^N\\alpha_j y^{(j)}\\mathbf{x}^{(j)}\n",
    "+ \\sum_{i=1}^N\\alpha_i\\\\\n",
    "&= \n",
    "\\sum_{i=1}^N\\alpha_i - \n",
    "\\frac{1}{2}\\sum_{i=1}^N\n",
    "\\sum_{j=1}^N\n",
    "\\alpha_i\n",
    "\\alpha_j\n",
    "y^{(i)}\n",
    "y^{(j)}\n",
    "(\\mathbf{x}^{(i)})^\\intercal\n",
    "\\mathbf{x}^{(j)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "* Dobili smo **dualni optimizacijski problem**:\n",
    "\n",
    "> **Maksimizirati** izraz\n",
    "> \\begin{align}\n",
    " \\sum_{i=1}^N\\alpha_i - \n",
    " \\frac{1}{2}\\sum_{i=1}^N\n",
    " \\sum_{j=1}^N\n",
    " \\alpha_i\n",
    " \\alpha_j\n",
    " y^{(i)}\n",
    " y^{(j)}\n",
    " (\\mathbf{x}^{(i)})^\\intercal\n",
    " \\mathbf{x}^{(j)}\n",
    " \\end{align}\n",
    "> tako da:\n",
    "> \\begin{align*}\n",
    " \\alpha_i &\\geq 0,\\quad i=1,\\dots,N \\\\ \n",
    " \\sum_{i=1}^N\\alpha_i y^{(i)} &= 0\n",
    " \\end{align*}\n",
    "\n",
    "* Također vrijedi KKT-uvjet:\n",
    "$$\n",
    "\\alpha_i\\big(y^{(i)} h(\\mathbf{x}^{(i)})-1\\big) = 0\n",
    "$$\n",
    "\n",
    "\n",
    "* Ovo je i dalje problem kvadratnog programiranja, međutim broj varijabli se promijenio\n",
    "  * Primarni problem: $n+1$ varijabli\n",
    "  * Dualni problem: $N$ varijabli\n",
    "  \n",
    "  \n",
    "* Dakle, prijelaz u dualni problem se računalno isplati ako $N\\ll n$\n",
    "  \n",
    "  \n",
    "* Općenito, složenost kvadratnog programiranja od $n$ varijabli je $\\mathcal{O}(n^3)$\n",
    "  * Posebni algoritmi su efikasniji: **slijedna minimalna optimizacija (SMO)** ima $\\mathcal{O}(n^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "* Već smo izračunali:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{w} &= \\sum_{i=1}^N \\alpha_i y^{(i)}\\mathbf{x}^{(i)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "* Uvrštavanjem:\n",
    "$$\n",
    "\\begin{equation}\n",
    "h(\\mathbf{x})=\n",
    "\\underbrace{\\mathbf{w}^\\intercal\\mathbf{x}+w_0}_{\\text{Primarno}} = \n",
    "\\underbrace{\\sum_{i=1}^N \\alpha_i y^{(i)}\\mathbf{x}^\\intercal\\mathbf{x}^{(i)} + w_0}_{\\text{Dualno}}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "* Kako bismo klasificirali primjer $\\mathbf{x}$, računamo skalarni produkt između $\\mathbf{x}$ i svih primjera $\\mathbf{x}^{(i)}$ iz skupa $\\mathcal{D}$, pomnožen s težinom $\\alpha_i$ i predznakom $\\mathcal{y}^(i)$\n",
    "\n",
    "\n",
    "* Računanje skalarnog produkta $\\mathbf{x}^\\intercal\\mathbf{x}^{(i)}$ je zapravo računanje sličnosti između vektora $\\mathbf{x}$ i $\\mathbf{x}^{(i)}$, budući da:\n",
    "$$\n",
    "\\mathbf{x}^\\intercal\\mathbf{y} = \\sum_{i=1}^n x_i y_i\n",
    "$$\n",
    "(produkt će biti to veći što se vektori podudaraju u više komponenenata)\n",
    "\n",
    "\n",
    "* Dakle, umjesto da pohranjujemo težine $\\mathbf{w}$, trebamo pohraniti primjere i njihove oznake\n",
    "  * Umjesto $h(\\mathbf{x}|\\mathbf{w})$ imamo $h(\\mathbf{x}|\\boldsymbol\\alpha,\\mathcal{D})$\n",
    "  \n",
    "  \n",
    "* Složenost modela sada ovisi o broju primjera $\\Rightarrow$ **neparametarski model**\n",
    "\n",
    "\n",
    "* Zaključak: ako se trenira tako da se rješava primarni problem, SVM je parametarski model, a ako se rješava dualni problem, onda je neparametarski \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Potporni vektori\n",
    "\n",
    "* Iz KKT-uvjeta\n",
    "$$\n",
    "\\alpha_i\\big(y^{(i)} h(\\mathbf{x}^{(i)})-1\\big) = 0\n",
    "$$\n",
    "slijedi da za svaki primjer $\\mathbf{x}^{(i)}$ iz $\\mathcal{D}$ vrijedi \n",
    "$$\n",
    "\\alpha_i=0\n",
    "$$\n",
    "ili \n",
    "$$\n",
    "y^{(i)}h(\\mathbf{x}^{(i)})=1\n",
    "$$\n",
    "\n",
    "\n",
    "* To znači da je se u izrazu za model pojavljuju samo vektori koji leže točno na ravnini maksimalne margine $\\Rightarrow$ **potporni vektori** (engl. *support vectors*)\n",
    "\n",
    "\n",
    "* Svi ostali vektori za koje $\\alpha_i=0$ uopće ne utječu na izlaz modela i možemo ih zanemariti kada radimo predikciju\n",
    "\n",
    "\n",
    "* Alternativni pogled: hiperravnina (u primarnom problemu) definirana je linearnom kombinacijom potpornih vektora (u dualnom problemu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seven_X = sp.array([[2,1], [2,3], [1,2], [3,2], [5,2], [5,4], [6,3]])\n",
    "seven_y = sp.array([1, 1, 1, 1, -1, -1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEACAYAAACuzv3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd209306450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_problem(seven_X, seven_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(seven_X, seven_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWYAAAD7CAYAAABZqT4/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2093e2650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_problem(seven_X, seven_y, svc.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.predict(sp.array([1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.predict(sp.array([6, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.predict(sp.array([3.5, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.99980469],\n",
       "       [ 1.99921875],\n",
       "       [ 2.99921875],\n",
       "       [ 0.99980469],\n",
       "       [-0.99960937],\n",
       "       [-1.00019531],\n",
       "       [-1.99960938]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.decision_function(seven_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.99707031e-01,   1.46484375e-04,  -4.99853516e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.dual_coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  2.],\n",
       "       [ 5.,  4.],\n",
       "       [ 3.,  2.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.support_vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rekonstrukcija primarnog problema\n",
    "\n",
    "* Nakon što je model naučen, možemo rekonstruirati primarne varijable, odnosno težine $\\mathbf{w}$ i $w_0$\n",
    "\n",
    "\n",
    "* Težine $\\mathbf{w}$:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{w} &= \\sum_{i=1}^N \\alpha_i y^{(i)}\\mathbf{x}^{(i)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "* Pomak $w_0$: za potporne vektore $\\mathbf{x}^{(i)}\\in S$ vrijedi\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "y^{(i)} h(\\mathbf{x}) &= 1\\\\ \n",
    "y^{(i)} \\Big(\\sum_{j\\in S} \\alpha_j y^{(j)}(\\mathbf{x}^{(i)})^\\intercal\\mathbf{x}^{(j)} + w_0\\Big) &= y^{(i)} y^{(i)}\\\\\n",
    "w_0 &= y^{(i)} - \\sum_{j\\in S} \\alpha_j y^{(j)}(\\mathbf{x}^{(i)})^\\intercal\\mathbf{x}^{(j)}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "* $w_0$ možemo izračunati na temelju jednog primjera $\\mathbf{x}^{(i)}$. Međutim, radi numeričke stabilnosti, bolje je uprosječiti izračun nad svim potpornim vektorima:\n",
    "\n",
    "\n",
    "$$\n",
    "w_0 = \\frac{1}{|S|}\\sum_{i\\in S} \\Big( y^{(i)} - \\sum_{j\\in S} \\alpha_j y^{(j)}(\\mathbf{x}^{(i)})^\\intercal\\mathbf{x}^{(j)}\\Big)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def w0(X, y, dc, sv) :\n",
    "    s = 0\n",
    "    for i in sv :\n",
    "        r = 0\n",
    "        for alpha,j in zip(dc,sv) :\n",
    "            r += -alpha*sp.dot(X[i],X[j])\n",
    "        s += y[i] - r\n",
    "    return s / float(len(sv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9995117187499982"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0(seven_X, seven_y, svc.dual_coef_[0], svc.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.99951172])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -9.99707031e-01,  -2.92968750e-04]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h_primal(x, w, w0):\n",
    "    return sp.dot(w,x)+ w0\n",
    "def h_dual(x, X, y, dc, sv):\n",
    "    return sum([ -alpha * sp.dot(x,X[i]) for alpha,i in zip(dc, sv)]) + w0(X, y, dc, sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.99980469],\n",
       "       [ 1.99921875],\n",
       "       [ 2.99921875],\n",
       "       [ 0.99980469],\n",
       "       [-0.99960937],\n",
       "       [-1.00019531],\n",
       "       [-1.99960938]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.decision_function(seven_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.99980469]),\n",
       " array([ 1.99921875]),\n",
       " array([ 2.99921875]),\n",
       " array([ 0.99980469]),\n",
       " array([-0.99960938]),\n",
       " array([-1.00019531]),\n",
       " array([-1.99960938])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda x : h_primal(x,svc.coef_,svc.intercept_),seven_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9998046874999988,\n",
       " 1.9992187499999989,\n",
       " 2.999218749999998,\n",
       " 0.99980468749999929,\n",
       " -0.99960937500000036,\n",
       " -1.0001953124999989,\n",
       " -1.9996093750000021]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda x : h_dual(x,seven_X,seven_y,svc.dual_coef_[0],svc.support_),seven_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Je li ovo jedini način za treniranje SVM-a?\n",
    "\n",
    "* Nije. Umjesto Lagrangeovih multiplikatora, mogli smo problem kvadratnog programiranja riješiti na neki drugi način\n",
    "\n",
    "\n",
    "* Također, mogli smo ostati na primarnom problemu, i riješiti ga npr. stohastičkim gradijentnim spustom uz penalizaciju (algoritam *Pegasos*)\n",
    "\n",
    "\n",
    "* Postoji niz SVM solvera \n",
    "  * https://cseweb.ucsd.edu/~akmenon/ResearchExam.pdf\n",
    "  * https://mitpress.mit.edu/sites/default/files/titles/content/9780262026253_sch_0001.pdf\n",
    "  \n",
    "\n",
    "* Međutim, prednost dualne formulacije je da omogućava **jezgreni trik**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meka margina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sažetak\n",
    "\n",
    "* Logistička regresija je **diskriminativan klasifikacijski model** s probabilističkim izlazom\n",
    "  \n",
    "  \n",
    "* Koristi se **logistička funkcija gubitka** odnosno **pogreška unakrsne entropije**\n",
    "\n",
    "\n",
    "* Optimizacija se provodi **gradijentnim spustom**, a prenaučenost se može spriječiti **regularizacijom**\n",
    "\n",
    "\n",
    "* Model **odgovara generativnom modelu** s normalno distribuiranim izglednostima i dijeljenom kovarijacijskom matricom, ali je broj parametara logističke regresije manji \n",
    "\n",
    "\n",
    "* Logistička regresija vrlo je dobar algoritam koji **nema        nedostatke** koje imaju klasifikacija regresijom i perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_problem(X, y, h=None, surfaces=True) :\n",
    "    '''\n",
    "    Plots a two-dimensional labeled dataset (X,y) and, if function h(x) is given, \n",
    "    the decision boundaries (surfaces=False) or decision surfaces (surfaces=True)\n",
    "    '''\n",
    "    assert X.shape[1] == 2, \"Dataset is not two-dimensional\"\n",
    "    if h!=None : \n",
    "        # Create a mesh to plot in\n",
    "        r = 0.02  # mesh resolution\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, r),\n",
    "                             np.arange(y_min, y_max, r))\n",
    "        XX=np.c_[xx.ravel(), yy.ravel()]\n",
    "        try:\n",
    "            Z_test = h(XX)\n",
    "            if shape(Z_test) == () :\n",
    "                # h returns a scalar when applied to a matrix; map explicitly\n",
    "                Z = sp.array(map(h,XX))\n",
    "            else :\n",
    "                Z = Z_test\n",
    "        except ValueError:\n",
    "            # can't apply to a matrix; map explicitly\n",
    "            Z = sp.array(map(h,XX))\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        if surfaces :\n",
    "            plt.contourf(xx, yy, Z, cmap=plt.cm.Pastel1)\n",
    "        else :\n",
    "            plt.contour(xx, yy, Z)\n",
    "    # Plot the dataset\n",
    "    scatter(X[:,0],X[:,1],c=y, cmap=plt.cm.Paired,marker='o',s=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
